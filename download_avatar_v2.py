#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ˜æ—¥æ–¹èˆŸå¹²å‘˜å¤´åƒæ‰¹é‡ä¸‹è½½å™¨ v2
ä½¿ç”¨ MediaWiki API
"""

import requests
import os
import time
import re
from urllib.parse import unquote
from concurrent.futures import ThreadPoolExecutor, as_completed

class AvatarCrawlerV2:
    def __init__(self, save_dir="operator_avatars"):
        self.save_dir = save_dir
        self.api_url = "https://prts.wiki/api.php"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        os.makedirs(save_dir, exist_ok=True)
    
    def get_category_members(self, category, limit=500):
        """
        è·å–åˆ†ç±»ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        """
        print(f"æ­£åœ¨è·å–åˆ†ç±» '{category}' ä¸­çš„æ–‡ä»¶...")
        
        params = {
            'action': 'query',
            'list': 'categorymembers',
            'cmtitle': f'Category:{category}',
            'cmlimit': limit,
            'cmtype': 'file',
            'format': 'json'
        }
        
        try:
            response = self.session.get(self.api_url, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            members = data.get('query', {}).get('categorymembers', [])
            return members
        except Exception as e:
            print(f"âœ— APIè¯·æ±‚å¤±è´¥: {e}")
            return []
    
    def get_file_url(self, filename):
        """
        è·å–æ–‡ä»¶çš„å®é™…ä¸‹è½½URL
        """
        params = {
            'action': 'query',
            'titles': filename,
            'prop': 'imageinfo',
            'iiprop': 'url',
            'format': 'json'
        }
        
        try:
            response = self.session.get(self.api_url, params=params, timeout=30)
            data = response.json()
            pages = data.get('query', {}).get('pages', {})
            
            for page in pages.values():
                imageinfo = page.get('imageinfo', [])
                if imageinfo:
                    return imageinfo[0].get('url')
        except Exception as e:
            print(f"âœ— è·å–æ–‡ä»¶URLå¤±è´¥: {e}")
        
        return None
    
    def download_image(self, url, filename):
        """
        ä¸‹è½½å•å¼ å›¾ç‰‡
        """
        try:
            filepath = os.path.join(self.save_dir, filename)
            
            if os.path.exists(filepath):
                print(f"âŠ™ å·²å­˜åœ¨: {filename}")
                return True
            
            print(f"ğŸ“¥ ä¸‹è½½ä¸­: {filename}")
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            
            with open(filepath, 'wb') as f:
                f.write(response.content)
            
            size_kb = len(response.content) / 1024
            print(f"âœ“ æˆåŠŸ: {filename} ({size_kb:.1f} KB)")
            return True
            
        except Exception as e:
            print(f"âœ— å¤±è´¥: {filename} - {e}")
            return False
    
    def download_all_avatars(self, max_workers=5):
        """
        ä¸‹è½½æ‰€æœ‰å¹²å‘˜å¤´åƒ
        """
        print("=" * 60)
        print("æ˜æ—¥æ–¹èˆŸå¹²å‘˜å¤´åƒæ‰¹é‡ä¸‹è½½å™¨ v2")
        print("=" * 60)
        print()
        
        # è·å–åˆ†ç±»ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        members = self.get_category_members('å¹²å‘˜å¤´åƒ')
        
        if not members:
            print("\nâš ï¸  æœªæ‰¾åˆ°æ–‡ä»¶ï¼Œå°è¯•æœç´¢æ‰€æœ‰åŒ…å«'å¤´åƒ'çš„æ–‡ä»¶...")
            members = self.search_avatar_files()
        
        if not members:
            print("âœ— æœªæ‰¾åˆ°ä»»ä½•å¤´åƒæ–‡ä»¶")
            return
        
        print(f"\næ‰¾åˆ° {len(members)} ä¸ªå¤´åƒæ–‡ä»¶")
        print(f"ä¿å­˜ç›®å½•: {os.path.abspath(self.save_dir)}\n")
        
        # è·å–æ–‡ä»¶URLå¹¶ä¸‹è½½
        tasks = []
        for member in members:
            title = member.get('title', '')
            if title.startswith('File:') or title.startswith('æ–‡ä»¶:'):
                tasks.append(title)
        
        print(f"å‡†å¤‡ä¸‹è½½ {len(members)} ä¸ªæ–‡ä»¶...\n")
        
        success_count = 0
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {}
            
            for member in members:
                # å¦‚æœmemberä¸­å·²æœ‰URLï¼Œç›´æ¥ä½¿ç”¨
                if 'url' in member:
                    url = member['url']
                    filename = member.get('name', '')
                else:
                    # å¦åˆ™é€šè¿‡APIè·å–
                    title = member.get('title', '')
                    if not (title.startswith('File:') or title.startswith('æ–‡ä»¶:')):
                        continue
                    url = self.get_file_url(title)
                    filename = title.replace('File:', '').replace('æ–‡ä»¶:', '')
                
                if url and filename:
                    # æ¸…ç†æ–‡ä»¶å
                    filename = unquote(filename)
                    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
                    
                    future = executor.submit(self.download_image, url, filename)
                    futures[future] = filename
            
            # ç­‰å¾…å®Œæˆ
            for future in as_completed(futures):
                if future.result():
                    success_count += 1
        
        print("\n" + "=" * 60)
        print(f"ä¸‹è½½å®Œæˆï¼æˆåŠŸ: {success_count}/{len(tasks)}")
        print("=" * 60)
    
    def search_avatar_files(self):
        """
        æœç´¢åŒ…å«'å¤´åƒ'çš„æ–‡ä»¶ï¼ˆæ”¯æŒåˆ†é¡µï¼‰
        """
        print("æ­£åœ¨æœç´¢æ‰€æœ‰å¤´åƒæ–‡ä»¶...")
        
        avatar_images = []
        continue_token = None
        
        while True:
            params = {
                'action': 'query',
                'list': 'allimages',
                'aifrom': 'å¤´åƒ',
                'ailimit': 500,
                'format': 'json'
            }
            
            if continue_token:
                params['aicontinue'] = continue_token
            
            try:
                response = self.session.get(self.api_url, params=params, timeout=30)
                data = response.json()
                
                all_images = data.get('query', {}).get('allimages', [])
                
                # æ”¶é›†æ‰€æœ‰åŒ…å«"å¤´åƒ"çš„å›¾ç‰‡
                for img in all_images:
                    name = img.get('name', '')
                    url = img.get('url', '')
                    
                    # åªè·å–ä»¥"å¤´åƒ_"å¼€å¤´çš„æ–‡ä»¶
                    if name.startswith('å¤´åƒ_'):
                        avatar_images.append({
                            'title': f"File:{name}",
                            'name': name,
                            'url': url,
                            'ns': 6
                        })
                    elif not name.startswith('å¤´åƒ'):
                        # å¦‚æœé‡åˆ°ä¸æ˜¯ä»¥"å¤´åƒ"å¼€å¤´çš„æ–‡ä»¶ï¼Œè¯´æ˜å·²ç»è¶…å‡ºèŒƒå›´
                        return avatar_images
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¤šç»“æœ
                if 'continue' in data and 'aicontinue' in data['continue']:
                    continue_token = data['continue']['aicontinue']
                    print(f"å·²æ‰¾åˆ° {len(avatar_images)} ä¸ªå¤´åƒï¼Œç»§ç»­è·å–...")
                else:
                    break
                    
            except Exception as e:
                print(f"æœç´¢å¤±è´¥: {e}")
                break
        
        return avatar_images


def main():
    crawler = AvatarCrawlerV2(save_dir="operator_avatars")
    crawler.download_all_avatars(max_workers=5)


if __name__ == "__main__":
    main()






