/**
 * éŸ³é¢‘å¤„ç†å™¨å®ç°
 * æ”¯æŒæ ¼å¼è½¬æ¢ã€å‹ç¼©ã€éŸ³è´¨è°ƒæ•´ç­‰åŠŸèƒ½
 */

import * as path from 'path';
import { promises as fs } from 'fs';
import { existsSync } from 'fs';
import { createLogger } from '../../../logger';


import type {
  IFileProcessor,
  ProcessorType,
  ProcessingOptions,
  ProcessingResult,
} from '../types';

import type { AudioProcessingOptions } from '../../types';

const logger = createLogger('AudioProcessor');

// éŸ³é¢‘å¤„ç†ç›¸å…³ç±»å‹å®šä¹‰
interface AudioMetadata {
  format: string;
  duration: number;
  bitrate: number;
  sampleRate: number;
  channels: number;
  codec: string;
  size: number;
}

/**
 * éŸ³é¢‘å¤„ç†å™¨
 * ä½¿ç”¨FFmpegè¿›è¡ŒéŸ³é¢‘å¤„ç†
 */
export class AudioProcessor implements IFileProcessor {
  readonly type: ProcessorType = 'audio';

  private ffmpeg: any = null;
  private isInitialized = false;

  /**
   * åˆå§‹åŒ–éŸ³é¢‘å¤„ç†å™¨
   */
  async initialize(): Promise<void> {
    logger.info('ğŸµ [AudioProcessor] åˆå§‹åŒ–éŸ³é¢‘å¤„ç†å™¨...');

    try {
      // å°è¯•åŠ è½½FFmpegåº“
      try {
        this.ffmpeg = require('fluent-ffmpeg');
        logger.info('âœ… [AudioProcessor] FFmpegåº“åŠ è½½æˆåŠŸ');
      } catch (error) {
        console.warn('âš ï¸ [AudioProcessor] FFmpegåº“æœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼');
        // åˆ›å»ºæ¨¡æ‹ŸFFmpegå¯¹è±¡
        this.ffmpeg = this.createMockFFmpeg();
      }

      this.isInitialized = true;
      logger.info('âœ… [AudioProcessor] éŸ³é¢‘å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ');
    } catch (error) {
      console.error('âŒ [AudioProcessor] éŸ³é¢‘å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * å¤„ç†éŸ³é¢‘æ–‡ä»¶
   */
  async process(
    inputPath: string,
    outputPath: string,
    options: ProcessingOptions
  ): Promise<ProcessingResult> {
    this.ensureInitialized();

    if (options.type !== 'audio') {
      throw new Error('å¤„ç†é€‰é¡¹ç±»å‹ä¸åŒ¹é…ï¼šæœŸæœ› audio');
    }

    const audioOptions = options as AudioProcessingOptions;
    const startTime = Date.now();

    logger.info(`ğŸµ [AudioProcessor] å¼€å§‹å¤„ç†éŸ³é¢‘: ${inputPath}`);

    try {
      // æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
      if (!existsSync(inputPath)) {
        throw new Error(`è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: ${inputPath}`);
      }

      // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
      const outputDir = path.dirname(outputPath);
      await fs.mkdir(outputDir, { recursive: true });

      // è·å–éŸ³é¢‘å…ƒæ•°æ®
      const metadata = await this.getAudioMetadata(inputPath);
      logger.info(
        `ğŸ“Š [AudioProcessor] éŸ³é¢‘ä¿¡æ¯: ${this.formatDuration(metadata.duration)}, ${metadata.bitrate}kbps, ${metadata.sampleRate}Hz`
      );

      // ç¡®å®šè¾“å‡ºæ ¼å¼
      const outputFormat = this.determineOutputFormat(outputPath, audioOptions.format);

      // æ‰§è¡ŒéŸ³é¢‘å¤„ç†
      await this.processAudio(inputPath, outputPath, audioOptions, outputFormat);

      // è·å–å¤„ç†åçš„æ–‡ä»¶ä¿¡æ¯
      const processedStats = await fs.stat(outputPath);
      const processingTime = Date.now() - startTime;

      logger.info(`âœ… [AudioProcessor] éŸ³é¢‘å¤„ç†å®Œæˆ: ${outputPath}, è€—æ—¶: ${processingTime}ms`);

      return {
        success: true,
        processedPath: outputPath,
        processedSize: processedStats.size,
        processingTime,
        data: {
          originalSize: metadata.size,
          processedSize: processedStats.size,
          compressionRatio: (metadata.size - processedStats.size) / metadata.size,
          duration: metadata.duration,
          originalFormat: metadata.format,
          processedFormat: outputFormat,
          originalBitrate: metadata.bitrate,
          processedBitrate: audioOptions.bitrate || metadata.bitrate,
          sampleRate: audioOptions.sampleRate || metadata.sampleRate,
          channels: audioOptions.channels || metadata.channels,
        },
      };
    } catch (error) {
      console.error(`âŒ [AudioProcessor] éŸ³é¢‘å¤„ç†å¤±è´¥: ${inputPath}:`, error);

      return {
        success: false,
        error: `éŸ³é¢‘å¤„ç†å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`,
        processingTime: Date.now() - startTime,
      };
    }
  }

  /**
   * æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ”¯æŒå¤„ç†
   */
  supports(mimeType: string): boolean {
    const supportedTypes = [
      'audio/mpeg',
      'audio/mp3',
      'audio/wav',
      'audio/wave',
      'audio/x-wav',
      'audio/ogg',
      'audio/vorbis',
      'audio/aac',
      'audio/x-aac',
      'audio/mp4',
      'audio/m4a',
      'audio/flac',
      'audio/x-flac',
      'audio/webm',
      'audio/opus',
    ];

    return supportedTypes.includes(mimeType.toLowerCase());
  }

  /**
   * è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
   */
  async getFileInfo(filePath: string): Promise<Record<string, any>> {
    this.ensureInitialized();

    try {
      const metadata = await this.getAudioMetadata(filePath);

      return {
        duration: metadata.duration,
        durationFormatted: this.formatDuration(metadata.duration),
        bitrate: metadata.bitrate,
        sampleRate: metadata.sampleRate,
        channels: metadata.channels,
        channelsDescription: this.getChannelsDescription(metadata.channels),
        format: metadata.format,
        codec: metadata.codec,
        fileSize: metadata.size,
        quality: this.getQualityDescription(metadata.bitrate, metadata.sampleRate),
      };
    } catch (error) {
      console.error(`âŒ [AudioProcessor] è·å–éŸ³é¢‘ä¿¡æ¯å¤±è´¥: ${filePath}:`, error);
      throw error;
    }
  }

  // ============= ç§æœ‰æ–¹æ³• =============

  /**
   * ç¡®ä¿å¤„ç†å™¨å·²åˆå§‹åŒ–
   */
  private ensureInitialized(): void {
    if (!this.isInitialized || !this.ffmpeg) {
      throw new Error('éŸ³é¢‘å¤„ç†å™¨æœªåˆå§‹åŒ–');
    }
  }

  /**
   * è·å–éŸ³é¢‘å…ƒæ•°æ®
   */
  private async getAudioMetadata(filePath: string): Promise<AudioMetadata> {
    return new Promise((resolve, reject) => {
      try {
        this.ffmpeg.ffprobe(filePath, (err: any, metadata: any) => {
          if (err) {
            console.error(`âŒ [AudioProcessor] è·å–éŸ³é¢‘å…ƒæ•°æ®å¤±è´¥: ${filePath}:`, err);
            reject(new Error(`æ— æ³•è¯»å–éŸ³é¢‘å…ƒæ•°æ®: ${err.message}`));
            return;
          }

          const audioStream = metadata.streams?.find(
            (stream: any) => stream.codec_type === 'audio'
          );
          if (!audioStream) {
            reject(new Error('æ–‡ä»¶ä¸­æœªæ‰¾åˆ°éŸ³é¢‘æµ'));
            return;
          }

          const result: AudioMetadata = {
            format: metadata.format?.format_name || 'unknown',
            duration: parseFloat(metadata.format?.duration || '0'),
            bitrate: parseInt(audioStream.bit_rate || '0') / 1000, // è½¬æ¢ä¸ºkbps
            sampleRate: parseInt(audioStream.sample_rate || '0'),
            channels: parseInt(audioStream.channels || '0'),
            codec: audioStream.codec_name || 'unknown',
            size: parseInt(metadata.format?.size || '0'),
          };

          resolve(result);
        });
      } catch (error) {
        reject(error);
      }
    });
  }

  /**
   * æ‰§è¡ŒéŸ³é¢‘å¤„ç†
   */
  private async processAudio(
    inputPath: string,
    outputPath: string,
    options: AudioProcessingOptions,
    outputFormat: string
  ): Promise<void> {
    return new Promise((resolve, reject) => {
      try {
        let command = this.ffmpeg(inputPath);

        // è®¾ç½®éŸ³é¢‘ç¼–è§£ç å™¨
        command = this.setAudioCodec(command, outputFormat);

        // è®¾ç½®æ¯”ç‰¹ç‡
        if (options.bitrate) {
          command = command.audioBitrate(options.bitrate);
          logger.info(`ğŸ”§ [AudioProcessor] è®¾ç½®æ¯”ç‰¹ç‡: ${options.bitrate}kbps`);
        }

        // è®¾ç½®é‡‡æ ·ç‡
        if (options.sampleRate) {
          command = command.audioFrequency(options.sampleRate);
          logger.info(`ğŸ”§ [AudioProcessor] è®¾ç½®é‡‡æ ·ç‡: ${options.sampleRate}Hz`);
        }

        // è®¾ç½®å£°é“æ•°
        if (options.channels) {
          command = command.audioChannels(options.channels);
          logger.info(`ğŸ”§ [AudioProcessor] è®¾ç½®å£°é“æ•°: ${options.channels}`);
        }

        // è®¾ç½®è¾“å‡ºæ ¼å¼
        command = command.format(outputFormat);

        // æ·»åŠ è¿›åº¦ç›‘å¬
        command.on('progress', (progress: any) => {
          if (progress.percent) {
            logger.info(`ğŸµ [AudioProcessor] å¤„ç†è¿›åº¦: ${Math.round(progress.percent)}%`);
          }
        });

        // æ·»åŠ é”™è¯¯ç›‘å¬
        command.on('error', (err: any) => {
          console.error(`âŒ [AudioProcessor] FFmpegå¤„ç†é”™è¯¯:`, err);
          reject(new Error(`éŸ³é¢‘å¤„ç†å¤±è´¥: ${err.message}`));
        });

        // æ·»åŠ å®Œæˆç›‘å¬
        command.on('end', () => {
          logger.info(`âœ… [AudioProcessor] FFmpegå¤„ç†å®Œæˆ: ${outputPath}`);
          resolve();
        });

        // å¼€å§‹å¤„ç†
        command.save(outputPath);
      } catch (error) {
        reject(error);
      }
    });
  }

  /**
   * è®¾ç½®éŸ³é¢‘ç¼–è§£ç å™¨
   */
  private setAudioCodec(command: any, format: string): any {
    switch (format) {
      case 'mp3':
        return command.audioCodec('libmp3lame');
      case 'aac':
        return command.audioCodec('aac');
      case 'ogg':
        return command.audioCodec('libvorbis');
      case 'wav':
        return command.audioCodec('pcm_s16le');
      default:
        return command;
    }
  }

  /**
   * ç¡®å®šè¾“å‡ºæ ¼å¼
   */
  private determineOutputFormat(
    outputPath: string,
    requestedFormat?: AudioProcessingOptions['format']
  ): string {
    if (requestedFormat) {
      return requestedFormat;
    }

    const ext = path.extname(outputPath).toLowerCase();
    const formatMap: Record<string, string> = {
      '.mp3': 'mp3',
      '.wav': 'wav',
      '.ogg': 'ogg',
      '.aac': 'aac',
      '.m4a': 'aac',
    };

    return formatMap[ext] || 'mp3';
  }

  /**
   * æ ¼å¼åŒ–æ—¶é•¿æ˜¾ç¤º
   */
  private formatDuration(seconds: number): string {
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = Math.floor(seconds % 60);
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
  }

  /**
   * è·å–å£°é“æè¿°
   */
  private getChannelsDescription(channels: number): string {
    switch (channels) {
      case 1:
        return 'å•å£°é“';
      case 2:
        return 'ç«‹ä½“å£°';
      case 6:
        return '5.1ç¯ç»•å£°';
      case 8:
        return '7.1ç¯ç»•å£°';
      default:
        return `${channels}å£°é“`;
    }
  }

  /**
   * è·å–éŸ³è´¨æè¿°
   */
  private getQualityDescription(bitrate: number, sampleRate: number): string {
    if (bitrate >= 320 && sampleRate >= 44100) {
      return 'é«˜éŸ³è´¨';
    } else if (bitrate >= 192 && sampleRate >= 44100) {
      return 'æ ‡å‡†éŸ³è´¨';
    } else if (bitrate >= 128) {
      return 'ä¸€èˆ¬éŸ³è´¨';
    } else {
      return 'ä½éŸ³è´¨';
    }
  }

  /**
   * åˆ›å»ºæ¨¡æ‹ŸFFmpegå¯¹è±¡ï¼ˆå¼€å‘æµ‹è¯•ç”¨ï¼‰
   */
  private createMockFFmpeg(): any {
    logger.info('ğŸ§ª [AudioProcessor] åˆ›å»ºæ¨¡æ‹ŸFFmpegå¤„ç†å™¨');

    const mockFFmpeg = (input: string) => {
      logger.info(`ğŸ§ª [MockFFmpeg] å¤„ç†éŸ³é¢‘: ${input}`);

      return {
        audioBitrate: (bitrate: number) => {
          logger.info(`ğŸ§ª [MockFFmpeg] è®¾ç½®æ¯”ç‰¹ç‡: ${bitrate}kbps`);
          return mockFFmpeg(input);
        },

        audioFrequency: (sampleRate: number) => {
          logger.info(`ğŸ§ª [MockFFmpeg] è®¾ç½®é‡‡æ ·ç‡: ${sampleRate}Hz`);
          return mockFFmpeg(input);
        },

        audioChannels: (channels: number) => {
          logger.info(`ğŸ§ª [MockFFmpeg] è®¾ç½®å£°é“æ•°: ${channels}`);
          return mockFFmpeg(input);
        },

        audioCodec: (codec: string) => {
          logger.info(`ğŸ§ª [MockFFmpeg] è®¾ç½®ç¼–è§£ç å™¨: ${codec}`);
          return mockFFmpeg(input);
        },

        format: (format: string) => {
          logger.info(`ğŸ§ª [MockFFmpeg] è®¾ç½®è¾“å‡ºæ ¼å¼: ${format}`);
          return mockFFmpeg(input);
        },

        on: (event: string, callback: Function) => {
          logger.info(`ğŸ§ª [MockFFmpeg] æ³¨å†Œäº‹ä»¶ç›‘å¬: ${event}`);

          if (event === 'progress') {
            // æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
            setTimeout(() => callback({ percent: 50 }), 100);
            setTimeout(() => callback({ percent: 100 }), 200);
          } else if (event === 'end') {
            // æ¨¡æ‹Ÿå¤„ç†å®Œæˆ
            setTimeout(() => callback(), 300);
          }

          return mockFFmpeg(input);
        },

        save: async (outputPath: string) => {
          logger.info(`ğŸ§ª [MockFFmpeg] ä¿å­˜éŸ³é¢‘æ–‡ä»¶: ${outputPath}`);

          // åˆ›å»ºæ¨¡æ‹Ÿè¾“å‡ºæ–‡ä»¶
          const outputDir = path.dirname(outputPath);
          await fs.mkdir(outputDir, { recursive: true });
          await fs.writeFile(outputPath, `Mock processed audio from ${input}`);
        },
      };
    };

    // æ·»åŠ ffprobeæ–¹æ³•
    mockFFmpeg.ffprobe = (filePath: string, callback: Function) => {
      logger.info(`ğŸ§ª [MockFFmpeg] è·å–éŸ³é¢‘å…ƒæ•°æ®: ${filePath}`);

      setTimeout(() => {
        const mockMetadata = {
          streams: [
            {
              codec_type: 'audio',
              codec_name: 'mp3',
              bit_rate: '128000',
              sample_rate: '44100',
              channels: '2',
            },
          ],
          format: {
            format_name: 'mp3',
            duration: '180.5',
            size: '1024000',
          },
        };

        callback(null, mockMetadata);
      }, 100);
    };

    return mockFFmpeg;
  }

  /**
   * æ‰¹é‡éŸ³é¢‘å¤„ç†
   */
  async batchProcess(
    inputPaths: string[],
    outputDir: string,
    options: AudioProcessingOptions,
    onProgress?: (completed: number, total: number) => void
  ): Promise<ProcessingResult[]> {
    this.ensureInitialized();

    logger.info(`ğŸµ [AudioProcessor] å¼€å§‹æ‰¹é‡å¤„ç† ${inputPaths.length} ä¸ªéŸ³é¢‘æ–‡ä»¶`);

    const results: ProcessingResult[] = [];

    for (let i = 0; i < inputPaths.length; i++) {
      const inputPath = inputPaths[i]!;
      const fileName = path.basename(inputPath);
      const nameWithoutExt = path.parse(fileName).name;
      const outputFormat = options.format || 'mp3';
      const outputPath = path.join(outputDir, `${nameWithoutExt}.${outputFormat}`);

      try {
        const result = await this.process(inputPath, outputPath, options);
        results.push(result);

        if (onProgress) {
          onProgress(i + 1, inputPaths.length);
        }
      } catch (error) {
        console.error(`âŒ [AudioProcessor] æ‰¹é‡å¤„ç†å¤±è´¥: ${inputPath}:`, error);
        results.push({
          success: false,
          error: `å¤„ç†å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`,
        });
      }
    }

    const successCount = results.filter((r) => r.success).length;
    logger.info(`âœ… [AudioProcessor] æ‰¹é‡å¤„ç†å®Œæˆï¼ŒæˆåŠŸ: ${successCount}/${inputPaths.length}`);

    return results;
  }

  /**
   * æå–éŸ³é¢‘å°é¢
   */
  async extractCover(inputPath: string, outputPath: string): Promise<boolean> {
    this.ensureInitialized();

    return new Promise((resolve) => {
      try {
        this.ffmpeg(inputPath)
          .outputOptions(['-an', '-vcodec copy'])
          .on('error', (err: any) => {
            console.warn(`âš ï¸ [AudioProcessor] æå–å°é¢å¤±è´¥: ${err.message}`);
            resolve(false);
          })
          .on('end', () => {
            logger.info(`ğŸ–¼ï¸ [AudioProcessor] éŸ³é¢‘å°é¢æå–å®Œæˆ: ${outputPath}`);
            resolve(true);
          })
          .save(outputPath);
      } catch (error) {
        console.warn(`âš ï¸ [AudioProcessor] æå–å°é¢å¼‚å¸¸:`, error);
        resolve(false);
      }
    });
  }

  /**
   * éŸ³é¢‘é™å™ªå¤„ç†
   */
  async denoise(inputPath: string, outputPath: string): Promise<ProcessingResult> {
    this.ensureInitialized();

    const startTime = Date.now();
    logger.info(`ğŸ”‡ [AudioProcessor] å¼€å§‹éŸ³é¢‘é™å™ª: ${inputPath}`);

    return new Promise((resolve) => {
      try {
        this.ffmpeg(inputPath)
          .audioFilters('highpass=f=200,lowpass=f=3000')
          .on('error', (err: any) => {
            resolve({
              success: false,
              error: `é™å™ªå¤„ç†å¤±è´¥: ${err.message}`,
              processingTime: Date.now() - startTime,
            });
          })
          .on('end', async () => {
            const processedStats = await fs.stat(outputPath);

            resolve({
              success: true,
              processedPath: outputPath,
              processedSize: processedStats.size,
              processingTime: Date.now() - startTime,
              data: {
                operation: 'denoise',
                filters: 'highpass=f=200,lowpass=f=3000',
              },
            });
          })
          .save(outputPath);
      } catch (error) {
        resolve({
          success: false,
          error: `é™å™ªå¤„ç†å¼‚å¸¸: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`,
          processingTime: Date.now() - startTime,
        });
      }
    });
  }
}
